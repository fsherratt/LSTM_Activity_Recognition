hyper_paramaters:
  save_hparam: true
  hparam_file: "conf/hparam.yaml"

  hparam_log_file: "C:/Users/Freddie/Documents/PhD/Data/Results/22_20211021_1452_pre-trained-model-personalisation/hparam.log"
  hparam_result_file: "C:/Users/Freddie/Documents/PhD/Data/Results/22_20211021_1452_pre-trained-model-personalisation/result.log"

hardware_setup:
  use_gpu: true
  random_seed: 0

base_model:
  folder: "C:/Users/Freddie/Documents/PhD/Data/Results/22_20211021_1452_pre-trained-model-personalisation/Models/128x32-gen-base-model/model"
  model_name: "@HP_MODEL_NAME"

data:
  folder_gen: "C:/Users/Freddie/Documents/PhD/Data/Results/22_20211021_1452_pre-trained-model-personalisation/Data/General_Pop"
  folder: "C:/Users/Freddie/Documents/PhD/Data/Results/22_20211021_1452_pre-trained-model-personalisation/Data/Bespoke_Pop"

  test_train_split: "@HP_TEST_TRAIN_SPLIT"
  verbose: true

  percentage_train: 70
  max_label_difference: 1

  episode_offset: "@HP_EPISODE_OFFSET"
  training_samples: "@HP_TRAINING_SAMPLES"
  test_samples: 5000

  x_validation_exclude: "@HP_VALIDATION_EXCLUDE"

  data_settings:
    num_timesteps: "@HP_TIMESTEPS"
    num_labels: "@HP_NUMBER_ACTIVITIES"
    skip: 2
    normalize: false
    label_heading: "activity"
    data_headings:
      - "r_ankle_accel_x"
      - "r_ankle_accel_y"
      - "r_ankle_accel_z"
      - "r_ankle_gyro_x"
      - "r_ankle_gyro_y"
      - "r_ankle_gyro_z"
      - "l_ankle_accel_x" # = r
      - "l_ankle_accel_y" # = -r
      - "l_ankle_accel_z" # = r
      - "l_ankle_gyro_x" # = -r
      - "l_ankle_gyro_y" # = r
      - "l_ankle_gyro_z" # = -r

    label_mapping:
      0: 0 # Walking
      1: 1 # Ramp Ascent
      2: 2 # Ranp Descent
      3: 3 # Stair Ascent
      4: 4 # Stair Descent
      5: 5 # Stop

model:
  config_file: "conf/model.yaml"

loss_func:
  type: "categorical_crossentropy"
  settings:
    from_logits: true

compile:
  optimizer: "adam"
  metrics:
    - "categorical_accuracy"

learning_rate: "@HP_LEARNING_RATE"

callbacks:
  use_tensorboard: true
  tensorboard:
    histogram_freq: 1

  use_early_stopping_threshold: false
  early_stopping_threshold: 0.96

  use_early_stopping: true
  early_stopping:
    monitor: "val_loss"
    verbose: 1
    patience: 3

  use_save_model: true
  save_model:
    verbose: 1
    save_weights_only: true
    period: 5

  use_learning_rate_scheduler: false

fit:
  batch_size: 100
  epochs: 1000
  shuffle: true
  steps_per_epoch: 21 # Train with x * batch_size per epoch
  verbose: 2

save:
  config: true
  final_model: true

  config_dir: "logs/conf/"
  tensorboard_dir: "logs/scalars/"
  model_dir: "logs/model/"
  history_dir: "logs/history/"
